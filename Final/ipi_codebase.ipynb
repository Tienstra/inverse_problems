{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a21XEeLe7ZxI"
   },
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vr8KnLSWtk_a",
    "outputId": "e58c6fa1-3ba8-4f1f-92fd-3f0a97fc4920"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive \n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AG9Mnd5J_ay5",
    "outputId": "841bb157-7e4c-4dd5-ebfb-d4ad83c8ba50"
   },
   "outputs": [],
   "source": [
    "#clean memory\n",
    "import gc\n",
    "try:\n",
    "    del images\n",
    "except:\n",
    "    pass\n",
    "gc.collect(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0SqbyCSRuzq"
   },
   "source": [
    "### File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-m5MUzMczvoh"
   },
   "outputs": [],
   "source": [
    "image_path = \"/content/gdrive/My Drive/Inverse Problems/Images/\"\n",
    "model_path = \"/content/gdrive/My Drive/Inverse Problems/Models/\"\n",
    "history_path = \"/content/gdrive/My Drive/Inverse Problems/CSV/\"\n",
    "graph_path = \"/content/gdrive/My Drive/Inverse Problems/Graphs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import savetxt, loadtxt\n",
    "\n",
    "import scipy.misc\n",
    "from skimage import img_as_float\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist, fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L0lSwXAvusmO"
   },
   "outputs": [],
   "source": [
    "data_dict = {\"mnist\": mnist.load_data(), \n",
    "             \"fashion_mnist\": fashion_mnist.load_data()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPtAPbHIDX9R"
   },
   "source": [
    "## Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H1yPaRqLt-0A"
   },
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yb161CnIPGlI"
   },
   "source": [
    "### Function to add noise/blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pGDonA4Y6rgz"
   },
   "outputs": [],
   "source": [
    "#Make noisy images \n",
    "\n",
    "def add_noise(x,y,delta):\n",
    "    x = x + delta * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "    y = y + delta * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "    x = np.clip(x, 0., 1.)\n",
    "    y = np.clip(y, 0., 1.)\n",
    "\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QuZyKmKl2NrZ"
   },
   "outputs": [],
   "source": [
    "#Make blurry images  \n",
    "\n",
    "def add_blur_noise(x,y,delta):\n",
    "    x = gaussian_filter(x_train, sigma=0.5) + delta * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "    y = gaussian_filter(x_test, sigma=0.5)   + delta * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "    x = np.clip(x, 0., 1.)\n",
    "    y = np.clip(y, 0., 1.)\n",
    "\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9Go7SZp7TeS"
   },
   "source": [
    "### Function to calulate PSNR and SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJLQqm1oJLOg"
   },
   "outputs": [],
   "source": [
    "def calculate_psnr(u, u_rec, n):\n",
    "    psnr_vec = np.zeros(n)\n",
    "    for i in range(0,n): \n",
    "        psnr_vec[i] = peak_signal_noise_ratio(u[i].reshape(28,28), u_rec[i].reshape(28,28))\n",
    "    \n",
    "    mean = round(np.mean(psnr_vec), 2)\n",
    "    return mean, psnr_vec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3MqA4hj0JPBP"
   },
   "outputs": [],
   "source": [
    "def calculate_ssim(u, u_rec, n):\n",
    "  ssim_vec = np.zeros(n)\n",
    "\n",
    "  for i in range(0, n): \n",
    "    ssim_vec[i] = ssim(u[i].reshape(28,28), u_rec[i].reshape(28,28), data_range=1)\n",
    "    \n",
    "  mean = round(np.mean(ssim_vec),2)\n",
    "  return mean, ssim_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22ENPe7NUrKI"
   },
   "source": [
    "### Function to Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RehhHlzMQDNe"
   },
   "outputs": [],
   "source": [
    "def plot_loss(history_dic):\n",
    "    iterations = list(range(1,len(history_dic['loss'])+1))\n",
    "    plt.plot(iterations,history_dic['loss'],label='training')\n",
    "    plt.plot(iterations,history_dic['val_loss'],label='validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(graph_path+'loss.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hR7us_4BGog3"
   },
   "source": [
    "### Box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-pmxKxwqGnsl"
   },
   "outputs": [],
   "source": [
    "def box_plot_psnr(data, title, labels):\n",
    "    fig, ax = plt.subplots(dpi=300,figsize=(4,2))\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(r'Noise $\\sigma$')\n",
    "    ax.set_ylabel('PSNR')\n",
    "    ax.boxplot(data, labels=labels)\n",
    "    #plt.savefig(image_path+'boxplot.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGvqksVhPLVU"
   },
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "id": "7G5FZ6dxGbUZ",
    "outputId": "6c7fc6e4-a889-4d3c-c838-bb30c8a1c0c1"
   },
   "outputs": [],
   "source": [
    "#show orginal images \n",
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(1, n):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "id": "W8qhGmFJ7Wlc",
    "outputId": "9896c88c-ba11-4df0-f4a6-5aa0eab06fca"
   },
   "outputs": [],
   "source": [
    "#show noisy images\n",
    "x_train_noisy, x_test_noisy = add_noise(x_train,x_test,0.25)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(1, n):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "id": "Vj2sJks2uO7r",
    "outputId": "05247ced-cca5-4c9e-beea-ceb6fda1fd43"
   },
   "outputs": [],
   "source": [
    "#show blurry + noisy images\n",
    "x_train_blurry, x_test_blurry = add_blur_noise(x_train,x_test,0.25)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(1, n):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(x_test_blurry[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pgEk4oHCHWTd"
   },
   "outputs": [],
   "source": [
    "noise_levels_dic = {'0.1':0.10, '0.2':0.2, '0.3':0.30, '0.4':0.4, \n",
    "                    '0.5': 0.50, '0.6':0.60, '0.7':0.7,'0.8':0.8,\n",
    "                    '0.9':0.9, '1':1\n",
    "                    }\n",
    "epochs = 100\n",
    "psnr_dic = {} \n",
    "mean_psnr_dic = {} \n",
    "ssim_dic = {} \n",
    "mean_ssim_dic = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfOGps3r6omi"
   },
   "source": [
    "## Autodenoising with CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFZsz4GDPYlm"
   },
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHUioxiQOUs9"
   },
   "outputs": [],
   "source": [
    "#The model\n",
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (7, 7, 32)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "#compile model \n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmus4sU8vGKU"
   },
   "source": [
    "## Training for Noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2IVO-92GJ2p"
   },
   "outputs": [],
   "source": [
    "for noise_level, delta in noise_levels_dic.items():\n",
    "    #make data \n",
    "    x_train_noisy, x_test_noisy = add_noise(x_train,x_test,delta)\n",
    "    save_name = \"_\".join(('noise_level ',noise_level))\n",
    "    #fit the model\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('Fitting model on data with noise level '+noise_level)\n",
    "    print('\\n')\n",
    "    history = autoencoder.fit(x_train_noisy, x_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=128,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(x_test_noisy, x_test))\n",
    "    \n",
    "    #Saves in a record of the training and validation loss\n",
    "    pd.DataFrame(history.history).to_csv(history_path+save_name+\".csv\")\n",
    "\n",
    "    autoencoder.save(model_path+save_name+\".h5\")\n",
    "\n",
    "    #evalute the model \n",
    "    print('\\n')\n",
    "    print('Evaluating Model')\n",
    "    print('\\n')\n",
    "    accuracy_train = history.model.evaluate(x_train_noisy,x_train,verbose=0)\n",
    "    accuracy_test = history.model.evaluate(x_test_noisy,x_test, verbose=0)\n",
    "\n",
    "    \n",
    "    plot_loss(history.history)\n",
    "\n",
    "    #plot\n",
    "    # encode and decode some digits\n",
    "    # note that we take them from the *test* set\n",
    "    print('Plotting')\n",
    "    print('\\n')\n",
    "    encoded_imgs = autoencoder.predict(x_test_noisy[:100])\n",
    "    decoded_imgs = autoencoder.predict(encoded_imgs)\n",
    "\n",
    "    n = 10  # how many digits we will display\n",
    "    plt.figure(figsize=(20, 4), dpi=300)\n",
    "    for i in range(1, n):\n",
    "        # display original noisy\n",
    "        ax = plt.subplot(2, n, i+1)\n",
    "        plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.savefig(image_path+\n",
    "                save_name+'.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    #calculate PSNR based on 5000 samples and saves in dictionary\n",
    "    mean_psnr_dic[noise_level], psnr_dic[noise_level]=calculate_psnr(x_test,x_test_noisy, 5000)\n",
    "\n",
    "    #calculate SSIM based on 5000 samples and saves in dictionary\n",
    "    mean_ssim_dic[noise_level], ssim_dic[noise_level] = calculate_ssim(x_test,x_test_noisy, 5000)\n",
    "\n",
    "# saves to csv file\n",
    "pd.DataFrame(mean_psnr_dic,index=mean_psnr_dic.keys()).to_csv(history_path+\"mean_psnr_noise.csv\")\n",
    "pd.DataFrame(mean_ssim_dic,index=mean_ssim_dic.keys()).to_csv(history_path+\"mean_ssim_noise.csv\")\n",
    "pd.DataFrame(psnr_dic,index=psnr_dic.keys()).to_csv(history_path+\"psnr_noise.csv\")\n",
    "pd.DataFrame(ssim_dic,index=ssim_dic.keys()).to_csv(history_path+\"ssim_noise.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use archived model\n",
    "\n",
    "Run this code if you have previously train the auto-encoders and saved the model in a file. Otherwise you can skip this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archived_mean_psnr_dic = {}\n",
    "archived_mean_ssim_dic = {}\n",
    "archived_psnr_dic = {}\n",
    "archived_ssim_dic = {}\n",
    "\n",
    "for noise_level, delta in noise_levels_dic.items():\n",
    "    #make data \n",
    "    x_train_noisy, x_test_noisy = add_noise(x_train,x_test,delta)\n",
    "    save_name = \"_\".join(('noise_level ',noise_level))\n",
    "    #Re-load the model\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('Loading model on data with noise level '+noise_level)\n",
    "    print('\\n')\n",
    "\n",
    "    autoencoder = load_model(model_path + save_name + \".h5\")\n",
    "\n",
    "    #plot\n",
    "    # encode and decode some digits\n",
    "    # note that we take them from the *test* set\n",
    "    print('Plotting')\n",
    "    print('\\n')\n",
    "    encoded_imgs = autoencoder.predict(x_test_noisy[:100])\n",
    "    decoded_imgs = autoencoder.predict(encoded_imgs)\n",
    "\n",
    "    n = 10  # how many digits we will display\n",
    "    plt.figure(figsize=(20, 4), dpi=300)\n",
    "    for i in range(1, n):\n",
    "        # display original noisy\n",
    "        ax = plt.subplot(2, n, i+1)\n",
    "        plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # plt.savefig(image_path+\n",
    "    #             save_name+'.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    #calculate PSNR based on 5000 samples and saves in dictionary\n",
    "    archived_mean_psnr_dic[noise_level], archived_psnr_dic[noise_level] = calculate_psnr(x_test, x_test_noisy, 100)\n",
    "\n",
    "    #calculate SSIM based on 5000 samples and saves in dictionary\n",
    "    archived_mean_ssim_dic[noise_level], archived_ssim_dic[noise_level] = calculate_ssim(x_test, x_test_noisy, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean PSNR : \", archived_mean_psnr_dic)\n",
    "print(\"Mean SSIM : \", archived_mean_ssim_dic)\n",
    "\n",
    "# ssim_data = []\n",
    "# for i in noise_levels_dic.keys():\n",
    "#     ssim_data.append(list(ssim_per_method_dic['ROF_TV'][i].values()))\n",
    "    \n",
    "# box_plot_psnr(psnr_per_method_dic['Perona_Malik'].values(), 'Perona-Malik', noise_levels_dic.keys())\n",
    "box_plot_simple(archived_psnr_dic.values(), 'Convolutional denoising auto-encoders', noise_levels_dic.keys())\n",
    "box_plot_simple(archived_ssim_dic.values(), 'Convolutional denoising auto-encoders', noise_levels_dic.keys(), y_label='SSIM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWkogzqJvOg8"
   },
   "source": [
    "## Fit for blurry + noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWi5bKDvXOis"
   },
   "outputs": [],
   "source": [
    "mean_psnr_dic_blur = {}\n",
    "mean_ssim_dic_blur = {}\n",
    "psnr_dic_blur = {}\n",
    "ssim_dic_blur = {}\n",
    "\n",
    "for noise_level, delta in noise_levels_dic.items():\n",
    "    #make data \n",
    "    x_train_noisy, x_test_noisy = add_blur_noise(x_train,x_test,delta)\n",
    "    save_name = \"_\".join(('blur_level_0.5_with_noise_level ',noise_level))\n",
    "    #fit the model\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('Fitting model on data with noise level '+noise_level)\n",
    "    print('\\n')\n",
    "    history = autoencoder.fit(x_train_noisy, x_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=128,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(x_test_noisy, x_test))\n",
    "    \n",
    "    #Saves in a record of the training and validation loss\n",
    "    pd.DataFrame(history.history).to_csv(history_path+save_name+\".csv\")\n",
    "\n",
    "    autoencoder.save(model_path+save_name+\".h5\")\n",
    "\n",
    "    #evalute the model \n",
    "    print('\\n')\n",
    "    print('Evaluating Model')\n",
    "    print('\\n')\n",
    "    accuracy_train = history.model.evaluate(x_train_noisy,x_train,verbose=0)\n",
    "    accuracy_test = history.model.evaluate(x_test_noisy,x_test, verbose=0)\n",
    "\n",
    "    \n",
    "    plot_loss(history.history)\n",
    "\n",
    "    #plot\n",
    "    # encode and decode some digits\n",
    "    # note that we take them from the *test* set\n",
    "    print('Plotting')\n",
    "    print('\\n')\n",
    "    encoded_imgs = autoencoder.predict(x_test_noisy[:100])\n",
    "    decoded_imgs = autoencoder.predict(encoded_imgs)\n",
    "\n",
    "    n = 10  # how many digits we will display\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(1, n):\n",
    "        # display original noisy\n",
    "        ax = plt.subplot(2, n, i+1)\n",
    "        plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.savefig(image_path+\n",
    "                save_name+'.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    #calculate PSNR based on 5000 samples and saves in dictionary\n",
    "    mean_psnr_dic_blur[noise_level], psnr_dic_blur[noise_level] = calculate_psnr(x_test, x_test_noisy,5000)\n",
    "    mean_ssim_dic_blur[noise_level], ssim_dic_blur[noise_level] = calculate_ssim(x_test, x_test_noisy, 5000)\n",
    "\n",
    "# saves to csv file\n",
    "# saves to csv file\n",
    "pd.DataFrame(mean_psnr_dic_blur,index=mean_psnr_dic_blur.keys()).to_csv(history_path+\"mean_psnr_blur.csv\")\n",
    "pd.DataFrame(mean_ssim_dic_blur,index=mean_ssim_dic_blur.keys()).to_csv(history_path+\"mean_ssim_blur.csv\")\n",
    "pd.DataFrame(psnr_dic_blur,index=psnr_dic_blur.keys()).to_csv(history_path+\"psnr_blur.csv\")\n",
    "pd.DataFrame(ssim_dic_blur,index=ssim_dic_blur.keys()).to_csv(history_path+\"ssim_blur.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "id": "63GnJ4IKG0HA",
    "outputId": "ff27c0ae-4319-4adf-dadc-82a4a3c28065"
   },
   "outputs": [],
   "source": [
    "box_plot_psnr(psnr_dic_blur.values(), 'Autoencoder for Blurred Data', noise_levels_dic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_psnr_dic_blur)\n",
    "print(mean_ssim_dic_blur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rObQbfyEvtlf"
   },
   "source": [
    "--- \n",
    "# Comparison for noisy data with other regularization methods\n",
    "\n",
    "- Perona-Malik\n",
    "- Rudin-Osher-Fatemi Total Variation (ROF TV)\n",
    "- Alternating Direction Method of Multipliers (ADMM)\n",
    "- Chambolle-Pock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8DtVb76z8z4"
   },
   "outputs": [],
   "source": [
    "# diffusion operator\n",
    "def L(u,coeff = lambda s : 1):\n",
    "    ue = np.pad(u,1,mode='edge') # padd edges to get array of size n+2 x n+2\n",
    "\n",
    "    # diffusion coefficient (central differences)\n",
    "    grad_norm = ((ue[2:,1:-1] - ue[:-2,1:-1])/(2/n))**2 + ((ue[1:-1,2:] - ue[1:-1,:-2])/(2/n))**2\n",
    "    c = np.pad(coeff(grad_norm),1,mode='edge')\n",
    "\n",
    "    # diffusion term (combination of forward and backward differences)\n",
    "    uxx = ((c[1:-1,1:-1] + c[2:,1:-1])*(ue[2:,1:-1]-ue[1:-1,1:-1]) - (c[:-2,1:-1]+c[1:-1,1:-1])*(ue[1:-1,1:-1]-ue[:-2,1:-1]))/(2/n**2)\n",
    "    uyy = ((c[1:-1,1:-1] + c[1:-1,2:])*(ue[1:-1,2:]-ue[1:-1,1:-1]) - (c[1:-1,:-2]+c[1:-1,1:-1])*(ue[1:-1,1:-1]-ue[1:-1,:-2,]))/(2/n**2)\n",
    "\n",
    "    return uxx + uyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8GcuChmYTZdZ"
   },
   "outputs": [],
   "source": [
    "noise_levels_dic = {'0.1':0.10, '0.2':0.20, '0.3':0.30, \n",
    "                    '0.4':0.40, '0.5':0.50, '0.6':0.60, \n",
    "                    '0.7':0.70, '0.8':0.80, '0.9':0.90, '1':1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o04YfQuFdpwf"
   },
   "source": [
    "### Perona-Malik and ROF TV regularisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YXG6eGtayDdT"
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "alpha = 10\n",
    "dt = 1e-6\n",
    "niter = 1001\n",
    "n = 28\n",
    "# coeff = lambda s : 1/(1+1e6*s)\n",
    "\n",
    "# #coeff for tv\n",
    "# coeff = lambda s : 1/((5)+np.sqrt(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yluBKDVx0cA5"
   },
   "outputs": [],
   "source": [
    "heat_method_dic={'Perona_Malik':lambda s : 1/(1+1e6*s), \n",
    "                  'ROF_TV': lambda s : 1/((5)+np.sqrt(s))}\n",
    "\n",
    "psnr_per_method_dic={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4BCuKAh5pjXZ"
   },
   "outputs": [],
   "source": [
    "def plot_reconstruction(data, n):\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 4), dpi=300)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    for i in range(n):\n",
    "        item = data[i]\n",
    "        \n",
    "        # display original noisy\n",
    "        ax = plt.subplot(2, n, i+1)\n",
    "        plt.imshow(item[0, :, :])\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(item[1, :, :])\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f73F-tEasDU_",
    "outputId": "c2ac6d40-460a-4940-8a73-d12a46d8684e"
   },
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage import img_as_float\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "\n",
    "#sample size\n",
    "#just testing to make sure it works \n",
    "sample_size = 2\n",
    "psnr_vec = np.zeros(sample_size)\n",
    "mean_psnr_dic = {}\n",
    "mean_psnr_per_method_dic = {}\n",
    "psnr_dic = {}\n",
    "psnr_per_method_dic = {}\n",
    "\n",
    "ssim_vec = {}\n",
    "ssim_dic = {}\n",
    "ssim_per_method_dic = {}\n",
    "\n",
    "# for noise_level, delta in noise_levels_dic.items():\n",
    "#     print('Noise level : ', noise_level)\n",
    "for method, coeff in heat_method_dic.items():\n",
    "    print('Method : ', method)\n",
    "    datas = np.zeros((sample_size, 2, 28, 28))\n",
    "    psnr_vec = np.zeros(sample_size)\n",
    "    \n",
    "\n",
    "    for noise_level, delta in noise_levels_dic.items():\n",
    "        print('Noise level : ', noise_level)\n",
    "    \n",
    "        \n",
    "        for i in range(0, sample_size):\n",
    "            f = img_as_float(x_train[i].reshape(28,28))\n",
    "            f_delta = f + np.random.normal(loc=0.0, scale=delta, size=f.shape)\n",
    "            f_delta = np.clip(f_delta, 0, 1)\n",
    "\n",
    "            if method=='Perona_Malik':\n",
    "            # solve evolution equation\n",
    "                u = np.zeros((n,n))\n",
    "                for k in range(niter-1):\n",
    "                    u = u - dt*(u - alpha*L(u,coeff)) + dt*f_delta\n",
    "            else:\n",
    "\n",
    "                # (image, weight=0.1, eps=0.0002, n_iter_max=200, multichannel=False, *, channel_axis=None)\n",
    "                #for ROF couldn't find one where Perona-Malik worked\n",
    "                u = denoise_tv_chambolle(f_delta, weight=alpha, eps=0.0002, n_iter_max=niter-1)\n",
    "                \n",
    " \n",
    "            # u = img_as_float(u)\n",
    "            psnr_vec[i] = peak_signal_noise_ratio(f,u)\n",
    "            ssim_vec[i] = ssim(f, u, data_range=1)\n",
    "\n",
    "            # Samples to display\n",
    "            if i < 10:\n",
    "                datas[i][0] = f_delta\n",
    "                datas[i][1] = u\n",
    "        \n",
    "        psnr_dic[noise_level] = psnr_vec.copy()\n",
    "        psnr_per_method_dic[method] = psnr_dic.copy()\n",
    "        \n",
    "        ssim_dic[noise_level] = ssim_vec.copy()\n",
    "        ssim_per_method_dic[method] = ssim_dic.copy()\n",
    "        \n",
    "        mean_psnr_dic[noise_level] = round(np.mean(psnr_vec), 2)\n",
    "        mean_psnr_per_method_dic[method] = mean_psnr_dic.copy()\n",
    "\n",
    "        # plot_reconstruction(datas, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jMelwD45UAU-",
    "outputId": "e08e404e-fa86-4362-bbcd-46dfec9c42d5"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ssim_data = []\n",
    "# for i in noise_levels_dic.keys():\n",
    "#     ssim_data.append(list(ssim_per_method_dic['Perona_Malik'][i].values()))\n",
    "\n",
    "box_plot_simple(psnr_per_method_dic['Perona_Malik'].values(), 'Perona Malik', noise_levels_dic.keys())\n",
    "box_plot_simple(ssim_per_method_dic['Perona_Malik'].values(), 'Perona Malik', noise_levels_dic.keys(), y_label='SSIM')\n",
    "\n",
    "\n",
    "# box_plot_psnr(psnr_per_method_dic['Perona_Malik'].values(), 'Perona-Malik', noise_levels_dic.keys())\n",
    "box_plot_simple(psnr_per_method_dic['ROF_TV'].values(), 'Total Variation', noise_levels_dic.keys())\n",
    "box_plot_simple(ssim_per_method_dic['ROF_TV'].values(), 'Total Variation', noise_levels_dic.keys(), y_label='SSIM')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for noise_level, delta in noise_levels_dic.items():\n",
    "    print(\"==== PC ====\")\n",
    "    print(\"Average PSNR for delta {:} is {:}\".format(delta, np.mean(psnr_per_method_dic['Perona_Malik'][noise_level])))\n",
    "    print(\"Average SSIM for delta {:} is {:}\".format(delta, np.mean(ssim_per_method_dic['Perona_Malik'][noise_level])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbpTA4xHp2da"
   },
   "source": [
    "Some thing wrong with the PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KueQcWY0rcT"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from skimage import data\n",
    "# from skimage.util import random_noise\n",
    "# from skimage.transform import resize\n",
    "\n",
    "# # parameters\n",
    "# sigma = 0.1\n",
    "# alpha = 1\n",
    "# dt = 1e-6\n",
    "# niter = 1001\n",
    "# n = 28\n",
    "# coeff = lambda s : 1/(1+1e6*s)\n",
    "\n",
    "# # diffusion operator\n",
    "# def L(u,coeff = lambda s : 1):\n",
    "#     ue = np.pad(u,1,mode='edge') # padd edges to get array of size n+2 x n+2\n",
    "\n",
    "#     # diffusion coefficient (central differences)\n",
    "#     grad_norm = ((ue[2:,1:-1] - ue[:-2,1:-1])/(2/n))**2 + ((ue[1:-1,2:] - ue[1:-1,:-2])/(2/n))**2\n",
    "#     c = np.pad(coeff(grad_norm),1,mode='edge')\n",
    "\n",
    "#     # diffusion term (combination of forward and backward differences)\n",
    "#     uxx = ((c[1:-1,1:-1] + c[2:,1:-1])*(ue[2:,1:-1]-ue[1:-1,1:-1]) - (c[:-2,1:-1]+c[1:-1,1:-1])*(ue[1:-1,1:-1]-ue[:-2,1:-1]))/(2/n**2)\n",
    "#     uyy = ((c[1:-1,1:-1] + c[1:-1,2:])*(ue[1:-1,2:]-ue[1:-1,1:-1]) - (c[1:-1,:-2]+c[1:-1,1:-1])*(ue[1:-1,1:-1]-ue[1:-1,:-2,]))/(2/n**2)\n",
    "\n",
    "#     return uxx + uyy\n",
    "\n",
    "# # noisy image\n",
    "# idx = np.random.randint(0,x_train.shape[0],2)\n",
    "\n",
    "# sigma=[0.1,0.5,1]\n",
    "# for s in sigma:\n",
    "#     print(s)\n",
    "#     for i in idx: \n",
    "#         f = img_as_float(x_train[i].reshape(28,28))\n",
    "#         f_delta = f + np.random.normal(loc=0.0, scale=s, size=f.shape)\n",
    "#         f_delta = np.clip(f_delta, 0, 1)\n",
    "\n",
    "#         # solve evolution equation\n",
    "#         # u = np.zeros((n,n))\n",
    "\n",
    "#         for k in range(niter-1):\n",
    "#             u = u - dt*(u - alpha*L(u,coeff)) + dt*f_delta\n",
    "\n",
    "#         \n",
    "\n",
    "\n",
    "#         print(peak_signal_noise_ratio(f,u)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJxu88702p7m"
   },
   "source": [
    "### Plot some samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYx6ygype6Xe"
   },
   "outputs": [],
   "source": [
    "# ax[0].imshow(f_delta)\n",
    "# ax[0].set_title('Noisy image')\n",
    "# ax[0].set_xticks([])\n",
    "# ax[0].set_yticks([])\n",
    "\n",
    "# ax[1].imshow(u_tv)\n",
    "# ax[1].set_title('Result NonLin TV')\n",
    "# ax[1].set_xticks([])\n",
    "# ax[1].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPFUbkGkwFjw"
   },
   "source": [
    "## Comparison for blurry + noisy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHZ0j1sKO9Yy"
   },
   "outputs": [],
   "source": [
    "# # grid \\Omega = [0,1]\n",
    "# n = 784\n",
    "# h = 1/(n-1)\n",
    "# x = np.linspace(0,1,n)\n",
    "\n",
    "# # parameters\n",
    "# niter = 10000\n",
    "# lmbda = 1\n",
    "\n",
    "\n",
    "# #Compute the D\n",
    "# def compute_D(u):\n",
    "#     D_xy = np.gradient(u.reshape(28,28))\n",
    "#     D_x  = D_xy[0]\n",
    "#     D_y  = D_xy[1]\n",
    "#     D = np.sqrt(np.abs(D_x)**2+ np.abs(D_y)**2)\n",
    "#     D=D.flatten()\n",
    "#     D=np.diag(-D) + np.diag(D[:-1],1)\n",
    "\n",
    "#     return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1PKnOhA_bw6"
   },
   "source": [
    "### Proximal Gradient Descent - Failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vECqlBJ5_QJY"
   },
   "outputs": [],
   "source": [
    "# def prox_grad(f,lmbda,D,alpha,niter):\n",
    "#     nu = np.zeros(D.shape[0])\n",
    "#     hist = np.zeros((niter,2))\n",
    "\n",
    "#     P = lambda nu : np.piecewise(nu, [np.abs(nu) <= lmbda, np.abs(nu) > lmbda], \n",
    "#                                  [lambda x : x, lambda x : lmbda*np.sign(x)])\n",
    "\n",
    "#     for k in range(0,niter):\n",
    "#         nu = P(nu - alpha*D@(D.T@nu - f))\n",
    "#         u = f - D.T@nu\n",
    "#         # primal = 0.5*np.linalg.norm(u - f)**2 + lmbda*np.linalg.norm(D@u,ord=1)\n",
    "#         # dual = -0.5*np.linalg.norm(D.T@nu) + f.dot(D.T@nu)\n",
    "#         # hist[k] = primal, dual\n",
    "\n",
    "#     return u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iju3XY8f6sv0"
   },
   "outputs": [],
   "source": [
    "# sample_size = 5\n",
    "# psnr_vec = np.zeros(sample_size)\n",
    "# mean_psnr_dic={}\n",
    "\n",
    "# for noise_level, delta in noise_levels_dic.items():\n",
    "#     save_name = \"_\".join(('blur_level_0.5_with_noise_level ',noise_level))\n",
    "#     for i in range(0,sample_size):\n",
    "#         f = x_train[i].reshape(28,28).flatten()\n",
    "#         f_delta = gaussian_filter(x_train[i], sigma=0.5) + delta * np.random.normal(loc=0.0, scale=1.0, size=x_train[i].shape)\n",
    "#         D = compute_D(f_delta)\n",
    "#         # proximal gradient on dual problem\n",
    "#         alpha = 1/np.linalg.norm(D)**2\n",
    "#         u_prox = prox_grad(f_delta.flatten(),lmbda,D,alpha,niter)\n",
    "#         psnr_vec[i]=peak_signal_noise_ratio(f,f_delta)\n",
    "#     mean_psnr_dic[noise_level]=np.mean(psnr_vec) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNcuo2pW5znI"
   },
   "source": [
    "### Plot some sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LpZeG7sInME9"
   },
   "outputs": [],
   "source": [
    "# # plot\n",
    "# fig,ax = plt.subplots(1,2)\n",
    "\n",
    "# plt.gray()\n",
    "\n",
    "# ax[0].imshow(f_delta.reshape(28,28))\n",
    "# ax[0].set_title('Noisy image')\n",
    "# ax[0].set_xticks([])\n",
    "# ax[0].set_yticks([])\n",
    "\n",
    "# ax[1].imshow(u_prox.reshape(28,28))\n",
    "# ax[1].set_title('Result Prox')\n",
    "# ax[1].set_xticks([])\n",
    "# ax[1].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHfVzSDmwRzy"
   },
   "source": [
    "### Admm - Failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7DzxvNd_Rsj"
   },
   "outputs": [],
   "source": [
    "# def admm(f,lmbda,D,rho,niter):\n",
    "#     m,n = D.shape\n",
    "#     nu = np.zeros(m)\n",
    "#     v = np.zeros(m)\n",
    "#     u = np.zeros(n)\n",
    "#     hist = np.zeros((niter,2))\n",
    "\n",
    "#     T = lambda v : np.piecewise(v, [v < -lmbda/rho, np.abs(v) <= lmbda/rho, v > lmbda/rho], \n",
    "#                                 [lambda x : x + lmbda/rho, lambda x : 0, lambda x : x - lmbda/rho])\n",
    "\n",
    "#     for k in range(0,niter):\n",
    "#         u = np.linalg.solve(np.eye(n) + rho*D.T@D, f + D.T@(rho*v - nu))\n",
    "#         v = T(D@u + nu/rho)\n",
    "#         nu = nu + rho*(D@u - v)\n",
    "\n",
    "#         # primal = 0.5*np.linalg.norm(u - f)**2 + lmbda*np.linalg.norm(D@u,ord=1)\n",
    "#         # dual = -0.5*np.linalg.norm(D.T@nu) + f.dot(D.T@nu)\n",
    "#         # hist[k] = primal, dual\n",
    "\n",
    "#     return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Np-abmSMlowe"
   },
   "outputs": [],
   "source": [
    "# ADMM\n",
    "#generate some data\n",
    "# delta = 0\n",
    "# idx=5\n",
    "# f_delta = gaussian_filter(x_train[idx], sigma=0.5) + delta * np.random.normal(loc=0.0, scale=1.0, size=x_train[idx].shape)\n",
    "\n",
    "# D = compute_D(f_delta)\n",
    "\n",
    "# rho = 1\n",
    "# lmbda = 1\n",
    "# u_admm = admm(f_delta.flatten(),lmbda,D,rho,niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fi9oCzS7GJN-"
   },
   "outputs": [],
   "source": [
    "# # plot\n",
    "# fig,ax = plt.subplots(1,2)\n",
    "\n",
    "# plt.gray()\n",
    "\n",
    "# ax[0].imshow(f_delta.reshape(28,28))\n",
    "# ax[0].set_title('Blurred image')\n",
    "# ax[0].set_xticks([])\n",
    "# ax[0].set_yticks([])\n",
    "\n",
    "# ax[1].imshow(u_admm.reshape(28,28))\n",
    "# ax[1].set_title('Result ADMM')\n",
    "# ax[1].set_xticks([])\n",
    "# ax[1].set_yticks([])\n",
    "\n",
    "# peak_signal_noise_ratio(x_train[idx].reshape(28,28),u_admm.reshape(28,28))\n",
    "\n",
    "# #result 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0htFdkPxLYkA"
   },
   "source": [
    "## ProxImaL lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tV0RroYntDKe",
    "outputId": "fa9129c7-ced1-4e48-fc12-cda9d941711a"
   },
   "outputs": [],
   "source": [
    "pip install proximal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "nlxO7rZkLery",
    "outputId": "daf11e82-dec0-452b-ab17-e89ea9086abb"
   },
   "outputs": [],
   "source": [
    "from proximal import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_levels_dic_2 = {'0.1':0.10, '0.2':0.20, '0.3':0.30, '0.4':0.40, '0.5':0.50, '0.6':0.60, '0.7':0.70, '0.8':0.80, '0.9':0.90, '1':1}\n",
    "# noise_levels_dic_2 = {'0.2':0.20, '0.5':0.50, '0.9':0.90}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chambolle-Pock - denoising\n",
    "\n",
    "Uncomment to try with gaussian blur + additive gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 794
    },
    "id": "k072fRcWqYbl",
    "outputId": "6a21a0eb-78a4-46c1-fc9f-86c7462186c1"
   },
   "outputs": [],
   "source": [
    "nb_samples = 100\n",
    "\n",
    "psnr_vec_pc = np.zeros(nb_samples)\n",
    "psnr_dic_pc = {}\n",
    "ssim_vec_pc = np.zeros(nb_samples)\n",
    "ssim_dic_pc = {}\n",
    "\n",
    "\n",
    "for noise_level, delta in noise_levels_dic_2.items():\n",
    "    \n",
    "    psnr_vec = np.zeros(nb_samples)\n",
    "    for i in range(nb_samples):\n",
    "        # Generate data.\n",
    "        I = x_train[i].reshape(28,28)\n",
    "        # b = gaussian_filter(I, sigma=0.5) + delta * np.random.normal(loc=0.0, scale=1.0, size=I.shape) \n",
    "        b = I + delta * np.random.normal(loc=0.0, scale=1.0, size=I.shape)\n",
    "        b = np.clip(b, 0, 1)\n",
    "\n",
    "        # Construct and solve problem.\n",
    "        x = Variable( I.shape )\n",
    "        prob = Problem(sum_squares(x - b) + .4 * norm1( grad(x) ) + nonneg(x))\n",
    "        prob.solve(solver='pc')\n",
    "\n",
    "        psnr_vec_pc[i] = peak_signal_noise_ratio(I, x.value)\n",
    "        ssim_vec_pc[i] = ssim(I, x.value, data_range=1)\n",
    "        \n",
    "        # Plot the original, noisy, and denoised images.\n",
    "#         fig = plt.figure(figsize=(10,10))\n",
    "#         ax = plt.subplot(1, 2, 1)\n",
    "#         plt.gray()\n",
    "#         plt.imshow(b)\n",
    "#         ax.get_xaxis().set_visible(False)\n",
    "#         ax.get_yaxis().set_visible(False)\n",
    "\n",
    "#         ax = plt.subplot(1, 2, 2)\n",
    "#         plt.gray()\n",
    "#         plt.imshow(x.value) # x.value is the optimal value of x.\n",
    "#         ax.get_xaxis().set_visible(False)\n",
    "#         ax.get_yaxis().set_visible(False)\n",
    "#         plt.show()\n",
    "    \n",
    "    psnr_dic_pc[noise_level] = psnr_vec_pc.copy()\n",
    "    ssim_dic_pc[noise_level] = ssim_vec_pc.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ojrGwDCqdyX"
   },
   "outputs": [],
   "source": [
    "# Plot one example of the original, noisy, and denoised images.\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plt.gray()\n",
    "plt.imshow(b)\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plt.gray()\n",
    "plt.imshow(x.value) # x.value is the optimal value of x.\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot_simple(psnr_dic_pc.values(), 'Chambolle-Pock', noise_levels_dic_2.keys(), y_label='PSNR')\n",
    "box_plot_simple(ssim_dic_pc.values(), 'Chambolle-Pock', noise_levels_dic_2.keys(), y_label='SSIM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for noise_level, delta in noise_levels_dic_2.items():\n",
    "    print(\"==== PC ====\")\n",
    "    print(\"Average PSNR for delta {:} is {:}\".format(delta, np.mean(psnr_dic_pc[noise_level])))\n",
    "    print(\"Average SSIM for delta {:} is {:}\".format(delta, np.mean(ssim_dic_pc[noise_level]))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADMM - denoising\n",
    "\n",
    "Uncomment to try with gaussian blur + additive gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 794
    },
    "id": "pxOFnEAzxNg9",
    "outputId": "838140e3-e27d-4f3a-d1da-437a771376ed"
   },
   "outputs": [],
   "source": [
    "nb_samples = 100\n",
    "psnr_vec = np.zeros(nb_samples)\n",
    "psnr_dic = {}\n",
    "ssim_vec = np.zeros(nb_samples)\n",
    "ssim_dic = {}\n",
    "\n",
    "\n",
    "for noise_level, delta in noise_levels_dic_2.items():\n",
    "    \n",
    "    psnr_vec = np.zeros(nb_samples)\n",
    "    for i in range(nb_samples):\n",
    "        # Generate data.\n",
    "        I = x_train[i].reshape(28,28)\n",
    "        # b = gaussian_filter(I, sigma=0.5) + delta * np.random.normal(loc=0.0, scale=1.0, size=I.shape) \n",
    "        b = I + delta * np.random.normal(loc=0.0, scale=1.0, size=I.shape)\n",
    "        b = np.clip(b, 0, 1)\n",
    "\n",
    "        # Construct and solve problem.\n",
    "        x = Variable( I.shape )\n",
    "        prob = Problem(sum_squares(x - b) + .4 * norm1( grad(x) ) + nonneg(x))\n",
    "        prob.solve(solver='admm')\n",
    "\n",
    "        psnr_vec[i] = peak_signal_noise_ratio(I, x.value)\n",
    "        ssim_vec[i] = ssim(I, x.value, data_range=1)\n",
    "        \n",
    "        # Plot the original, noisy, and denoised images.\n",
    "#         fig = plt.figure(figsize=(10,10))\n",
    "#         ax = plt.subplot(1, 2, 1)\n",
    "#         plt.gray()\n",
    "#         plt.imshow(b)\n",
    "#         ax.get_xaxis().set_visible(False)\n",
    "#         ax.get_yaxis().set_visible(False)\n",
    "\n",
    "#         ax = plt.subplot(1, 2, 2)\n",
    "#         plt.gray()\n",
    "#         plt.imshow(x.value) # x.value is the optimal value of x.\n",
    "#         ax.get_xaxis().set_visible(False)\n",
    "#         ax.get_yaxis().set_visible(False)\n",
    "#         plt.show()\n",
    "    \n",
    "    psnr_dic[noise_level] = psnr_vec.copy()\n",
    "    ssim_dic[noise_level] = ssim_vec.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original, noisy, and denoised images.\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plt.gray()\n",
    "plt.imshow(b)\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plt.gray()\n",
    "plt.imshow(x.value) # x.value is the optimal value of x.\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot_simple(psnr_dic.values(), 'ADMM', noise_levels_dic_2.keys(), y_label='PSNR')\n",
    "box_plot_simple(ssim_dic.values(), 'ADMM', noise_levels_dic_2.keys(), y_label='SSIM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for noise_level, delta in noise_levels_dic_2.items():\n",
    "    print(\"=======\")\n",
    "    print(\"Average PSNR for delta {:} is {:}\".format(delta, np.mean(psnr_dic[noise_level])))\n",
    "    print(\"Average SSIM for delta {:} is {:}\".format(delta, np.mean(ssim_dic[noise_level]))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ipi_codebase_(6).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
